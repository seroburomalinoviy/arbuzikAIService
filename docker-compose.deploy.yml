services:
  db:
    image: postgres:13
    command: ["postgres", "-c", "config_file=/etc/postgresql.conf"]
    environment:
      PGDATA: /var/lib/postgresql/data/pgdata
    env_file:
      - .env
    configs:
      - source: postgres_config
        target: /etc/postgresql.conf
    volumes:
      - type: volume
        source: pg_data
        target: /var/lib/postgresql/data
      - /home/porstgres/backups:/backups
    networks:
      - everywhere_overlay
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 7
        window: 51s

  rabbitmq:
    image: rabbitmq:3.10.7-management
    hostname: rabbitmq
    # container_name: rabbitmq
    # restart: always
    environment:
      # - RABBITMQ_CONFIG_FILE=/etc/rabbitmq/rabbitmq.conf
      # - RABBITMQ_DEFAULT_USER_FILE=/run/secrets/arbuzik
      # - RABBITMQ_DEFAULT_PASS_FILE=/run/secrets/arbuzik
      - RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=-rabbit disk_free_limit 2147483648
    env_file:
      - .env
    # secrets:
    #   - arbuzik
    configs:
      - source: rabbit_config
        target: /etc/rabbitmq/rabbitmq.conf
    ports:
      - "15672:15672"
      # - "5672:5672"
    healthcheck:
      test: rabbitmq-diagnostics check_port_connectivity
      interval: 10s
      timeout: 30s
      retries: 3
      start_period: 10s
    networks:
      - everywhere_overlay
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 5
        window: 50s

  redis:
    # container_name: redis
    image: redis:7.2
    command: ["redis-server", "/usr/local/etc/redis/redis.conf"]
      # - /bin/sh
      # - -c
      # # - Double dollars, so that the variable is not expanded by Docker Compose
      # # - Surround by quotes, so that the shell does not split the password
      # # - The ${variable:?message} syntax causes shell to exit with a non-zero
      # #   code and print a message, when the variable is not set or empty
      # - redis-server /usr/local/etc/redis.conf --requirepass "$${REDIS_PASSWORD:?REDIS_PASSWORD variable is not set}"
    # ports:
    #   - "6379:6379"
    # volumes:
      # - ./redis.conf:/usr/local/etc/redis/redis.conf
      # - /home/u603202/logs:/var/log/redis
    env_file:
      - .env
    configs:
      - source: redis_config
        target: /usr/local/etc/redis/redis.conf
        # uid: "103"
        # gid: "103"
        # mode: 0440
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - everywhere_overlay
    # restart:
    #   always
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 5
        window: 10s

  preclient:
    image: managernode:5000/preclient:latest
    command: ["python", "main.py"]
    env_file:
      - .env
    networks:
      - everywhere_overlay
    depends_on:
      - rabbitmq
      - redis
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
        delay: 50s
        max_attempts: 7
        window: 60s
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
        monitor: 10s
        failure_action: pause
      rollback_config:
        parallelism: 1
        delay: 20s
        failure_action: pause
        monitor: 0s 
        max_failure_ratio: 0
        order: start-first

  client:
    image: managernode:5000/client:latest
    command: ["python3.10", "main.py"]
    env_file:
      - .env
    depends_on:
      - rabbitmq
      - redis
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=all
      - PYTORCH_NO_CUDA_MEMORY_CACHING=1
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
    volumes:
      - type: volume
        source: media_volume
        target: /app/weights
      - type: volume
        source: voice_volume
        target: /app/media/user-voices
    networks:
      - everywhere_overlay
    extra_hosts:
      - "mangernode:192.168.0.100"
    deploy:
      mode: global
      # replicas: 1
      restart_policy:
        condition: any
        delay: 50s
        max_attempts: 6
        window: 60s
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
        monitor: 10s
        failure_action: pause
      rollback_config:
        parallelism: 1
        delay: 20s
        failure_action: pause
        monitor: 0s 
        max_failure_ratio: 0
        order: start-first


  bot:
    image: managernode:5000/django:latest
    command: ["python", "start_bot.py"]
    environment:
      POSTGRES_HOST: db
    env_file:
      - .env
    volumes:
      - type: volume
        source: voice_volume
        target: /app/media/user-voices
      - type: volume
        source: media_volume
        target: /app/media/data/
    networks:
      - everywhere_overlay
    depends_on:
      - db
      - rabbitmq
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
        delay: 30s
        max_attempts: 7
        window: 60s
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
        monitor: 10s
        failure_action: pause
      rollback_config:
        parallelism: 1
        delay: 20s
        failure_action: pause
        monitor: 0s 
        max_failure_ratio: 0
        order: start-first

  django:
    image: managernode:5000/django:latest
    command: sh -c 'python manage.py migrate --noinput && 
                    python manage.py collectstatic --noinput --clear &&
                    gunicorn config.asgi:application -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:80'
    environment:
      POSTGRES_HOST: db
    env_file:
      - .env
    volumes:
      - type: volume
        source: media_volume
        target: /app/media/data/
      - type: volume
        source: static_volume
        target: /app/static
    expose:
      - 8000
    networks:
      - everywhere_overlay
    depends_on:
      - db
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
        delay: 30s
        max_attempts: 7
        window: 60s
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
        monitor: 10s
        failure_action: pause
      rollback_config:
        parallelism: 1
        delay: 20s
        failure_action: pause
        monitor: 0s 
        max_failure_ratio: 0
        order: start-first

  proxy-server:
    image: nginx:latest
    ports:
      - "8000:80"
      - "8001:8001"
      - "3000:3000"
    env_file:
      - .env
    volumes:
      - type: volume
        source: static_volume
        target: /app/static
    depends_on:
      - payment-api
      - django
    configs:
     - source: nginx_config
       target: /etc/nginx/conf.d/default.conf
    networks:
      - everywhere_overlay
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
        delay: 30s
        max_attempts: 7
        window: 60s

  payment-api:
    image: managernode:5000/payment-api
    command: sh -c 'uvicorn api:app --host 0.0.0.0 --port 8001 --proxy-headers'
    expose:
      - 8001
    env_file:
      - .env
    networks:
      - everywhere_overlay
    depends_on:
      - bot
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 3
        window: 60s

  payment-listener:
    # container_name: payment-listener
    image: managernode:5000/payment-api
    command: ["python", "main.py"]
    env_file:
      - .env
    networks:
      - everywhere_overlay
    depends_on:
      - payment-api
      - rabbitmq
      - db
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 3
        window: 60s

  celery-scheduler:
    image: managernode:5000/django:latest
    command: celery --app config beat --loglevel=info --scheduler django_celery_beat.schedulers:DatabaseScheduler
    depends_on:
      - redis
      - bot
      - db
    environment:
      POSTGRES_HOST: db
    env_file:
      - .env
    networks:
      - everywhere_overlay
    volumes:
      - type: volume
        source: voice_volume
        target: /app/media/user-voices
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 3
        window: 60s

  celery-worker:
    image: managernode:5000/django:latest
    command: celery --app config worker --loglevel=info
    depends_on:
      - celery-scheduler
    env_file:
      - .env
    volumes:
      - type: volume
        source: voice_volume
        target: /app/media/user-voices
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 3
        window: 60s
    networks:
      - everywhere_overlay

  grafana-monitor:
    image: grafana/grafana-oss
    # restart: unless-stopped
    environment:
      - GF_LOG_LEVEL=info
      - GF_INSTALL_PLUGINS=redis-datasource
    expose:
      - 3000
    volumes:
      - grafana_storage:/var/lib/grafana
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 3
        window: 60s
    networks:
      - everywhere_overlay

  prometheus-scraper:
    image: prom/prometheus:latest
    container_name: prometheus-scraper
    hostname: prometheus-scraper
    command:
      - --config.file=/etc/prometheus/prometheus.yml
    restart: unless-stopped
    expose:
      - 9090
    configs:
      - source: prometheus_config
        target: /etc/prometheus/prometheus.yml
    volumes:
      - prometheus:/etc/prometheus/
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 3
        window: 60s
    networks:
      - everywhere_overlay

  prometheus-server:
    image: managernode:5000/preclient:latest
    command: sh -c 'uvicorn prometheus_server:app --host 0.0.0.0 --port 9001 --log-level info'
    env_file:
      - .env
    networks:
      - everywhere_overlay
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
        delay: 50s
        max_attempts: 7
        window: 60s
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
        monitor: 10s
        failure_action: pause
      rollback_config:
        parallelism: 1
        delay: 20s
        failure_action: pause
        monitor: 0s
        max_failure_ratio: 0
        order: start-first

  node-exporter:
    image: prom/node-exporter
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    container_name: exporter
    hostname: exporter
    command:
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --collector.filesystem.ignored-mount-points
      - ^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/)
    expose:
      - 9100
    restart: unless-stopped
    networks:
      - everywhere_overlay
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
        delay: 50s
        max_attempts: 7
        window: 60s
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
        monitor: 10s
        failure_action: pause
      rollback_config:
        parallelism: 1
        delay: 20s
        failure_action: pause
        monitor: 0s
        max_failure_ratio: 0
        order: start-first

  gpu-exporter:
    image: nvcr.io/nvidia/k8s/dcgm-exporter:3.3.8-3.6.0-ubuntu22.04
#    image: nvidia/dcgm-exporter
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    container_name: gpu_exporter
    hostname: gpu_exporter
#    command:
#      - --path.procfs=/host/proc
#      - --path.sysfs=/host/sys
#      - --collector.filesystem.ignored-mount-points
#      - ^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/)
    expose:
      - 9400
    environment:
      - DCGM_EXPORTER_NO_HOSTNAME=1
    cap_add:
        - SYS_ADMIN
    restart: unless-stopped
    networks:
      - everywhere_overlay
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      restart_policy:
        condition: any
        delay: 50s
        max_attempts: 7
        window: 60s
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
        monitor: 10s
        failure_action: pause
      rollback_config:
        parallelism: 1
        delay: 20s
        failure_action: pause
        monitor: 0s
        max_failure_ratio: 0
        order: start-first

  loki:
    image: grafana/loki:3.4.1
    container_name: loki
    configs:
      - source: loki_config
        target: /etc/loki/loki.yml
    command:
      - "--config.file=/etc/loki/loki.yml"
      - "--config.expand-env=true"
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role==manager
      update_config:
        order: stop-first
      resources:
        limits:
          memory: 1024M

  promtail:
    image: grafana/promtail:3.4.1
    container_name: promtail
    configs:
      - source: promtail_config
        target: /etc/promtail/promtail.yaml
    volumes:
      - promtail_data:/var/promtail
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/log:/var/log:ro
    environment:
      HOST_HOSTNAME: "{{.Node.Hostname}}"
    command:
      - "--config.file=/etc/promtail/promtail.yaml"
      - "--config.expand-env=true"
    deploy:
      mode: global
      update_config:
        order: stop-first
      resources:
        limits:
          memory: 512M


configs:
  promtail_config:
    file: ./promtail.yml
  loki_config:
    file: ./loki.yml
  rabbit_config:
    file: ./rabbitmq.conf
  nginx_config:
    file: ./nginx.conf
  postgres_config:
    file: ./postgres.conf
  redis_config:
    file: ./redis.conf
  prometheus_config:
    file: ./prometheus.yml

networks:
  everywhere_overlay:
    driver: overlay
    attachable: true

volumes:
  promtail_data:
  loki_data:
  static_volume:
  grafana_storage: {}
  pg_data:
  prometheus:
  media_volume:
    driver: local
    driver_opts:
      type: nfs
      o: addr=192.168.0.100,rw
      device: ":/home/remote/nfs/media"
  voice_volume:
    driver: local
    driver_opts:
      type: nfs
      o: addr=192.168.0.100,rw
      device: ":/home/remote/nfs/voices"

